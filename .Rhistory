# Read in df
list.files("G:/My Drive/THESIS/data/Market Project/RMWDatasets/")
setwd("C:/Users/User/github/")
source('R/econometric_functions.R')
source('R/econometric_functions.R')
source('Ranch-Climate-Weather/R/econometric_functions.R')
indexpaths= c("data/rasters/albers/pdsisc")
indexpaths= "data/rasters/albers/pdsisc"
indexnames = "pdsisc"
bufferdists = c(100,300,500,700)
lagname = "t"
datarange = c(0,1)
ninclusion = TRUE
central = TRUE
############################# load data #########################################################
print("Loading data...")
if(central == TRUE){
CompressedCows = readRDS("data/AMS/RData/AMS_monthly_central.rds")%>%na.omit() # Stored as CompressedCows
buffertype = "Central"
}else{
CompressedCows = readRDS("data/AMS/RData/AMS_monthly.rds")%>%na.omit() # Stored as CompressedCows
buffertype = ""
}
CompressedCows = readRDS("data/tables/rmw/ams_cattle_data.csv")%>%na.omit() # Stored as CompressedCows
setwd("C:/Users/User/github/Ranch-Climate-Weather/")
source('R/econometric_functions.R')
CompressedCows = readRDS("data/tables/rmw/ams_cattle_data.csv")%>%na.omit() # Stored as CompressedCows
CompressedCows = read.csv("data/tables/rmw/ams_cattle_data.csv")%>%na.omit() # Stored as CompressedCows
View(CompressedCows)
# This is the organized cattle market data
# if(central == TRUE){
CompressedCows = read.csv("data/tables/rmw/ams_cattle_data.csv")%>%na.omit() # Stored as CompressedCows
buffertype = "Central"
CompressedCows$date = paste0(as.character(CompressedCows$year),"-",
sprintf("%02d",CompressedCows$month))
CompressedCows$date = as.yearmon(CompressedCows$date,format = "%Y-%m")
# Date matching between climate and market data
startyear = min(CompressedCows$year)
lastyear = max(CompressedCows$year)
startmonth = min(CompressedCows$month)
if(str_sub(indexpath,-1)!= "/"){
indexpath = paste0(indexpath,"/")
}
files = list.files(indexpath, pattern ="*tif",full.names = TRUE) # climate variable
if(str_sub(indexpath,-1)!= "/"){
indexpath = paste0(indexpath,"/")
}
indexpath
indexpath= "data/rasters/albers/pdsisc"
# Date matching between climate and market data
startyear = min(CompressedCows$year)
lastyear = max(CompressedCows$year)
startmonth = min(CompressedCows$month)
if(str_sub(indexpath,-1)!= "/"){
indexpath = paste0(indexpath,"/")
}
files = list.files(indexpath, pattern ="*tif",full.names = TRUE) # climate variable
names = list.files(indexpath,pattern = "*tif")
files
indexpath
indexpath= "c:/Users/User/github/data/rasters/albers/pdsisc"
files = list.files(indexpath, pattern ="*tif",full.names = TRUE) # climate variable
files
names = list.files(indexpath,pattern = "*tif")
year1 = as.numeric(str_sub(names[1],-10,-7))
year2 = as.numeric(str_sub(names[length(names)],-10,-7))
if(startyear > year1){
year1 = startyear
files = files[as.numeric(str_sub(files,-10,-7))>=year1]
}
if(lastyear < year2){
year2 = lastyear
files = files[as.numeric(str_sub(files,-10,-7))<=year2]
}
colname = str_sub(names[1],0,-12)
interval1 = as.numeric(str_sub(files[1],-6,-5))
interval2 = as.numeric(str_sub(files[length(files)],-6,-5))
date1 = as.Date(paste0(year1,"-",interval1,"-1"),"%Y-%m-%d")
date2 = as.Date(paste0(year2,"-",interval2,"-1"),"%Y-%m-%d")
dates = seq.Date(date1,date2,by = "month")
dates = unlist(lapply(dates,as.yearmon))
intervaltype = max(unique(as.integer(str_sub(names,-6,-5))))
intervaltype
dates
# Create the list of climate rasters
rasters = raster::stack(files)
plot(rasters[[1]],zlim = datarange,col = topo.colors(35), legend = FALSE,main = toupper(colname), axes = F,box = F)
datarange
datarange = c(-7,7)
plot(rasters[[1]],zlim = datarange,col = topo.colors(35), legend = FALSE,main = toupper(colname), axes = F,box = F)
# Get info
print("Reading shapefiles, reprojecting and getting cell numbers...")
marketpath = "data/shapefiles/buffers"
srs = "+proj=aea +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
# These are the market radii we are testing
bufferlist = vector(mode = 'list',length = length(bufferdists))
names(bufferlist) = bufferdists
# They've been saved as shapefiles
for(i in seq(length(bufferdists))){
bufferlist[[i]] = readOGR(marketpath,paste0(buffertype,"Buffer_",bufferdists[i],"km"))
bufferlist[[i]] = spTransform(bufferlist[[i]],srs)
plot(rasters[[1]],zlim = datarange,col = topo.colors(35),
legend = FALSE,main = paste0(toupper(colname),"\n",bufferdists[[i]]," km"), axes = F,box = F)
plot(bufferlist[[i]], lwd = 1.5,lty = 12,add = T)
}
marketpath = "data/shapefiles/marketsheds/albers/central/fourradii"
marketpath
srs = "+proj=aea +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
# These are the market radii we are testing
bufferlist = vector(mode = 'list',length = length(bufferdists))
names(bufferlist) = bufferdists
# They've been saved as shapefiles
for(i in seq(length(bufferdists))){
bufferlist[[i]] = readOGR(marketpath,paste0(buffertype,"Buffer_",bufferdists[i],"km"))
bufferlist[[i]] = spTransform(bufferlist[[i]],srs)
plot(rasters[[1]],zlim = datarange,col = topo.colors(35),
legend = FALSE,main = paste0(toupper(colname),"\n",bufferdists[[i]]," km"), axes = F,box = F)
plot(bufferlist[[i]], lwd = 1.5,lty = 12,add = T)
}
########################## Get Cellnumbers within each buffer ################
# Next gets all of the raster cell ids that correspond to each market area shapefile, making the extractions faster
# First, I need the iterating variable to be first in the argument list for lapply
cellnumberSwitch = function(shapes,rasters){
cells = tabularaster::cellnumbers(rasters,shapes)
return(cells)
}
# Next, let's check if the file exists to possibly save time
cellrange = paste0(min(bufferdists),"_",max(bufferdists))
if(!file.exists(paste0("data/tables/",buffertype,"cellslist",cellrange,".rds"))){
print("Getting cell numbers for each radius")
cl = makeCluster(detectCores())
registerDoParallel(cl)
clusterExport(cl,c('cellnumbers'),envir=environment())
cellslist = pblapply(bufferlist,cellnumberSwitch, rasters, cl = cl)
stopCluster(cl)
saveRDS(cellslist,file = paste0("data/tables/",buffertype,"cellslist",cellrange,".rds"))
}else{
cellslist = readRDS(paste0("data/tables/",buffertype,"cellslist",cellrange,".rds"))
}
########################## function 1 ########################################
# Experimental new functions for speed
# This uses the prefab cell ids to extract raster values within each market areas, includes circles with nans
zonalMeans1 = function(iterate, rasters,cells){
means = cells%>%mutate(v = raster::extract(rasters[[iterate]],cell_))%>%
group_by(object_)%>%
na.omit()%>%
summarise(meanvalue = mean(v))
return(means)
}
# As above, but throws out observations with any nan values
zonalMeans2 = function(iterate, rasters,cells){
means = cells%>%dplyr::mutate(v = raster::extract(rasters[[iterate]],cell_))%>%
group_by(object_)%>%
summarise(meanvalue = mean(v))
return(means)
}
# This builds the climate dataset with one month worth of climate data for each observation
gridToTable = function(market,km,rasters,year1,year2,gridname,cells,ninclusion){
"
Author: Travis
This takes in a set of market polygons, a weather dataset (preconditioned), and a year range.
It uses the gridStackAvg function to build a tibble with averages of weather values within each
market polygon and out puts the value for each month within the specified years into a tibble.
markets = shapefile
weather = raster
year1, year2 = year range
gridname = 'string' (column name for grid output)
This is a good location to experiment with clusters, I think.
"
# Second get climate values
if(ninclusion == TRUE){
print(paste0("Getting climate means for the ",km," km radius..."))
cl = makeCluster(detectCores())
registerDoParallel(cl)
clusterExport(cl,c('%>%','extract','mutate','group_by','group_by','summarise'),envir=environment())
marketmeans = pblapply(seq(nlayers(rasters)), zonalMeans1, rasters, cells, cl = cl)
stopCluster(cl)
}else{
print(paste0("Getting climate means for the ",km," km radius..."))
cl = makeCluster(detectCores())
registerDoParallel(cl)
clusterExport(cl,c('%>%','extract','mutate','group_by','group_by','summarise'),envir=environment())
marketmeans = pblapply(seq(nlayers(rasters)), zonalMeans2, rasters, cells, cl = cl)
stopCluster(cl)
}
# Iterate through and build the dataset chunk by chunk
pb = progress_bar$new(total = year2 - year1)
pb$tick(0)
cows = data.frame(matrix(ncol = 5))
names(cows) = c("year","month","polyid","locale",gridname)
start = 1
N = nrow(market)
end = N
########################## Problem Zone ##########################
# The polygon IDs change when there are fewer polygons...duh
# How to associate these with the original polygon IDs?
# Generating Unique IDs
names(market) = c("locale","region")
IDs = as.numeric(sapply(slot(market, "polygons"), function(x) slot(x, "ID")))
#################### Problem Zone ################################
print(paste0("Building dataset for the ",km,"km market area..."))
r=1
intervaltype = 12
for (y in year1:year2){
pb$tick()
if(y == year2){intervaltype = interval2}
for(i in 1:intervaltype){
cows[start:end,1]=y
cows[start:end,2]=i
cows[start:end,3]=IDs
cows[start:end,4]=as.character(market$locale)
cows[start:end,5]=marketmeans[[r]][,2]
r = r+1
start= start + N
end = end + N
}
}
# polyids = unique(readRDS("data/Market Project/AMS/polyids.rds"))# original pairings
# marketnames = market@data$Locale
# IDs = data.frame(polyid = IDs,locale = marketnames)
# cows = full_join(cows,IDs,by = "locale")
# cows$PolyID = cows$PolyID.x
# cows$PolyID.x = NULL
cows%<>%na.omit
return(cows)
}
# Iterate through and build the dataset chunk by chunk
pb = progress_bar$new(total = year2 - year1)
pb$tick(0)
# This builds the climate dataset with one month worth of climate data for each observation
gridToTable = function(market,km,rasters,year1,year2,gridname,cells,ninclusion){
"
Author: Travis
This takes in a set of market polygons, a weather dataset (preconditioned), and a year range.
It uses the gridStackAvg function to build a tibble with averages of weather values within each
market polygon and out puts the value for each month within the specified years into a tibble.
markets = shapefile
weather = raster
year1, year2 = year range
gridname = 'string' (column name for grid output)
This is a good location to experiment with clusters, I think.
"
# Second get climate values
if(ninclusion == TRUE){
print(paste0("Getting climate means for the ",km," km radius..."))
cl = makeCluster(detectCores())
registerDoParallel(cl)
clusterExport(cl,c('%>%','extract','mutate','group_by','group_by','summarise'),envir=environment())
marketmeans = pblapply(seq(nlayers(rasters)), zonalMeans1, rasters, cells, cl = cl)
stopCluster(cl)
}else{
print(paste0("Getting climate means for the ",km," km radius..."))
cl = makeCluster(detectCores())
registerDoParallel(cl)
clusterExport(cl,c('%>%','extract','mutate','group_by','group_by','summarise'),envir=environment())
marketmeans = pblapply(seq(nlayers(rasters)), zonalMeans2, rasters, cells, cl = cl)
stopCluster(cl)
}
# Iterate through and build the dataset chunk by chunk
pb = progress_bar$new(total = year2 - year1)
pb$tick(0)
cows = data.frame(matrix(ncol = 5))
names(cows) = c("year","month","polyid","locale",gridname)
start = 1
N = nrow(market)
end = N
########################## Problem Zone ##########################
# The polygon IDs change when there are fewer polygons...duh
# How to associate these with the original polygon IDs?
# Generating Unique IDs
names(market) = c("locale","region")
IDs = as.numeric(sapply(slot(market, "polygons"), function(x) slot(x, "ID")))
#################### Problem Zone ################################
print(paste0("Building dataset for the ",km,"km market area..."))
r=1
intervaltype = 12
for (y in year1:year2){
pb$tick()
if(y == year2){intervaltype = interval2}
for(i in 1:intervaltype){
cows[start:end,1]=y
cows[start:end,2]=i
cows[start:end,3]=IDs
cows[start:end,4]=as.character(market$locale)
cows[start:end,5]=marketmeans[[r]][,2]
r = r+1
start= start + N
end = end + N
}
}
# polyids = unique(readRDS("data/Market Project/AMS/polyids.rds"))# original pairings
# marketnames = market@data$Locale
# IDs = data.frame(polyid = IDs,locale = marketnames)
# cows = full_join(cows,IDs,by = "locale")
# cows$PolyID = cows$PolyID.x
# cows$PolyID.x = NULL
cows%<>%na.omit
return(cows)
}
############################  Get Climate Data ##############################
# Call Above function
print("Averaging climate values within each market area...")
climates = vector(mode = 'list',length = length(bufferlist))
for(i in seq(length(climates))){
climates[[i]] = gridToTable(bufferlist[[i]],names(bufferlist)[[i]],rasters,year1,year2,colname,cellslist[[i]],ninclusion)
}
############################ function 3  #####################################
print("Creating lagged monthly climate observations...")
setDateID = function(climatedf){
'
Create a Date-ID field for market averaged weather dataset
'
climatedf = climatedf%>%dplyr::mutate(date = as.yearmon(paste(year,month,sep = "-")))
climatedf$dateid = paste0(climatedf$date,"_",climatedf$polyid)
climatedf%<>%dplyr::select(year,month,polyid,locale,colname,date,dateid)
names(climatedf) = c("year","month","polyid","locale",colname,"date","dateid")
return(climatedf)
}
climatewids = pblapply(climates,setDateID)
View(climatewids)
View(climatewids[[1]])
############################ function 4  #####################################
print("Organizing numbers...")
longToTime = function(x){
"
This Creates a list of Dataframes for each radius from the long form data into
a time series format. It creates a dataframe with 24 extra columns, and in each
one the appropriate DateID for the number of corresponding months back. This is
then used to match with the precip info, which also has a DateID now.
"
empty = x%>%dplyr::select(date,polyid,dateid)%>%filter(date>=min(date)+2)
# This fills the DateIDs in
#empty[[colname]] = empty$DateID
pb = progress_bar$new(total = 24)
for(i in 0:24){
empty[[paste0(lagname,as.character(i))]] = paste0(empty$date - i/12,"_",empty$polyid)
pb$tick()
}
return(empty)
}
empty = longToTime(climatewids[[i]])
View(empty)
IDs = vector(mode = 'list',length = length(climatewids))
for(i in seq(length(IDs))){
IDs[[i]] = empty
}
############################ function 5 ######################################
# This function will, hopefully, match each DateID with the corresponding precip value and replace
# each with the precip value.
getClimate = function(x,data){x = data[[5]][which(data[[7]]%in%x)]}
############################ function 5 ######################################
# This function will, hopefully, match each DateID with the corresponding precip value and replace
# each with the precip value.
getClimate = function(x,data){x = data[[5]][which(data[[7]]%in%x)]}
for(y in seq(length(IDs))){
for(i in 4:28){IDs[[y]][i] = lapply(empty[i],FUN = getClimate,data = climatewids[[y]])}
}
View(IDs)
View(IDs[[3]])
